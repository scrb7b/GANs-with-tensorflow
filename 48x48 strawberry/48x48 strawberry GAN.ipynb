{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6b3930-86e9-4f9e-aa44-b4505d77d9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Flatten, Reshape, Input, BatchNormalization, Dropout\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, LeakyReLU\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a7cf8d-1b21-4630-91c8-04082c65f180",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = keras.utils.image_dataset_from_directory(\n",
    "    'straw/',\n",
    "    color_mode='rgb',\n",
    "    batch_size=100,\n",
    "    image_size=(48, 48),\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1957583-1919-4799-8f89-ceb3848e6d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_list = []\n",
    "\n",
    "for images, labels in dataset:\n",
    "    images_list.append(images)\n",
    "\n",
    "images = np.concatenate(images_list, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fe7d6b-190c-4e07-a850-d4b4079d6cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = images.shape[0]\n",
    "BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f4bd47-bc1d-4f59-a8a6-7319c0831ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = BUFFER_SIZE // BATCH_SIZE * BATCH_SIZE\n",
    "images = images[:BUFFER_SIZE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6992246-6d6d-4077-ad69-9545d3e4a8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf2c4d6-2fb3-44d9-a672-2c740233aa71",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e14d538-feba-4bc8-8fd9-60655aeeb291",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5170c9d6-e88c-482f-b57f-da980e2d8126",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b864c00-d13e-4d9a-be63-36e935e8ffe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = tf.keras.Sequential([\n",
    "    \n",
    "  Dense(6 * 6 * 512, activation='relu', input_shape=(hidden_dim,)), #6х6\n",
    "  BatchNormalization(),\n",
    "  LeakyReLU(),\n",
    "    \n",
    "  Reshape((6, 6, 512)),\n",
    "    \n",
    "  Conv2DTranspose(256, (5, 5), strides=(1, 1), padding='same', activation='relu'),\n",
    "  BatchNormalization(),\n",
    "  LeakyReLU(),\n",
    "\n",
    "  Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same', activation='relu'), #12x12\n",
    "  BatchNormalization(),\n",
    "  LeakyReLU(),\n",
    "\n",
    "  Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', activation='relu'), #24x24\n",
    "  BatchNormalization(),\n",
    "  LeakyReLU(),\n",
    "\n",
    "  Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', activation='sigmoid'), #48x48\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2886fb8a-ac2e-4596-9f87-9983c095d824",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = tf.keras.Sequential([\n",
    "\n",
    "Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[48, 48, 3]),\n",
    "LeakyReLU(),\n",
    "Dropout(0.3),\n",
    "\n",
    "Conv2D(128, (5, 5), strides=(2, 2), padding='same'),\n",
    "LeakyReLU(),\n",
    "Dropout(0.3),\n",
    "\n",
    "Conv2D(256, (5, 5), strides=(2, 2), padding='same'),\n",
    "LeakyReLU(),\n",
    "Dropout(0.3),\n",
    "    \n",
    "Flatten(),\n",
    "Dense(1)\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45956139-2963-4b0e-a0a3-d535e00e55dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c300f3-5721-4b44-b96f-527b0aa86c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "  loss = cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588ba9d2-f1d3-489c-a246-18243f2244e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "  real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "  fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "  total_loss = real_loss + fake_loss\n",
    "  return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbf2da7-7b5a-48d1-96d4-57ba5f5be861",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdf23b4-42ef-4656-a877-3daf63b6c13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images):\n",
    "  noise = tf.random.normal([BATCH_SIZE, hidden_dim])\n",
    "\n",
    "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "    generated_images = generator(noise, training=True) # generate img\n",
    "\n",
    "    real_output = discriminator(images, training=True) # gradient of real in disc\n",
    "    fake_output = discriminator(generated_images, training=True) # gradient of generated in disc\n",
    "\n",
    "    gen_loss = generator_loss(fake_output) # loss of generation \n",
    "    disc_loss = discriminator_loss(real_output, fake_output) # loss of discriminator\n",
    "\n",
    "  gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables) # calculate gradients \n",
    "  gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables) \n",
    "\n",
    "  generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables)) # apply optimizer \n",
    "  discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "  return gen_loss, disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db88ead7-714a-43ee-8dba-763d8f5ac85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = tf.random.normal([BATCH_SIZE, hidden_dim])\n",
    "generated_images = generator(noise, training=True)\n",
    "plt.imshow(generated_images[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5d971a-b9c1-4b31-a880-2e3e94400113",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def train(dataset, epochs):\n",
    "  history = []\n",
    "  MAX_PRINT_LABEL = 10\n",
    "  th = BUFFER_SIZE / (BATCH_SIZE * MAX_PRINT_LABEL)\n",
    "\n",
    "  for epoch in range(1, epochs + 1):\n",
    "    print(f'{epoch}/{EPOCHS}: ', end='')\n",
    "\n",
    "    start = time.time()\n",
    "    n = 0\n",
    "\n",
    "    gen_loss_epoch = 0\n",
    "    for image_batch in dataset:\n",
    "      gen_loss, disc_loss = train_step(image_batch)\n",
    "      gen_loss_epoch += K.mean(gen_loss)\n",
    "      if (n % th == 0): print('=', end='')\n",
    "      n += 1\n",
    "\n",
    "    history += [gen_loss_epoch / n]\n",
    "    print(': ' + str(history[-1]))\n",
    "    print('Время эпохи {} составляет {} секунд'.format(epoch, time.time() - start))\n",
    "\n",
    "  return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea734c7-5185-45b2-a32f-ae0686f27b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 3000\n",
    "history = train(train_dataset, EPOCHS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a350950-c892-41d2-a502-6735a8e3748e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2\n",
    "total = 2 * n + 1\n",
    "\n",
    "plt.figure(figsize=(total, total))\n",
    "\n",
    "num = 1\n",
    "for i in range(-n, n + 1):\n",
    "  for j in range(-n, n + 1):\n",
    "    ax = plt.subplot(total, total, num)\n",
    "    num += 1\n",
    "    img = generator.predict(np.expand_dims([0.5 * i / n, 0.5 * j / n], axis=0))\n",
    "    plt.imshow(img[0])\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3db042e-6b43-4626-81f6-d204bf085578",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.save('50x50_strawnerry_GAN_3000_EPOCHS_generator2.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c64030-27ce-4829-a9cc-278ff146b291",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.save('50x50_strawnerry_GAN_3000_EPOCHS_discriminator2.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3925f8-b350-492d-a5a7-6b77f3c09a2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
